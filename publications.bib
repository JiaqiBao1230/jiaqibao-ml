@article{BAO2024109894,
title = {Robust embedding regression for semi-supervised learning},
journal = {Pattern Recognition},
volume = {145},
pages = {109894},
year = {2024},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2023.109894},
url = {https://www.sciencedirect.com/science/article/pii/S0031320323005927},
author = {Jiaqi Bao and Mineichi Kudo and Keigo Kimura and Lu Sun},
keywords = {Feature selection, Semi-supervised learning, Ridge regression, Nuclear norm},
abstract = {To utilize both labeled data and unlabeled data in real-world applications, semi-supervised learning is widely used as an effective technique. However, most semi-supervised methods do not perform well when there are many noises and redundant information in the original data. To address these issues, in this paper, we proposed a novel approach called robust embedding regression (RER) for semi-supervised learning by inheriting the advantages of the existing semi-supervised learning, robust linear regression, and low-rank representation techniques. Specifically, RER constructs a more robust and accurate graph by adaptively arranging the weight coefficient for each data point. Furthermore, the low-rank representation is introduced to reduce the negative influence of the redundant features and noises residing in the original data while the graph construction. More importantly, the proper norms are imposed on both the reconstruction and regularization terms to further improve the robustness and earn feature/sample selection. We designed an effective iterative algorithm to optimize the problem of RER. Comprehensive experimental results conducted on both synthetic and real-world datasets indicate that RER is superior in classification and clustering performance and robust to different types of noise compared with the existing semi-supervised methods.}
}